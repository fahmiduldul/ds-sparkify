{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6geHzXZ67cXj"
      },
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faokFFT9FS47"
      },
      "source": [
        "In this part of notebook we will try to train the model using feature extracted dataframe and make model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h40s2Xu6Fvv4"
      },
      "source": [
        "### Setup Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GKcHtxR9BXm",
        "outputId": "37ef5160-72b8-489a-9381-174c18ee5a30"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcM8P6Qf9KuW",
        "outputId": "1a3bc077-ae56-4592-bbc4-45580d5a6496"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tpxRRrfGL3u"
      },
      "source": [
        "### Import Needed Library, Initialize Spark and Load Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PENBvBwp9QDX"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "import pyspark.sql.functions as F\r\n",
        "import pyspark.sql.types as T\r\n",
        "\r\n",
        "from pyspark.ml.classification import GBTClassifier\r\n",
        "from pyspark.ml.feature import VectorAssembler\r\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\r\n",
        "import pandas as pd"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUguiUJd-xFX"
      },
      "source": [
        "spark = SparkSession.builder.appName('sparkify-train').getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuIpWq-z_xm_",
        "outputId": "6fb6c71b-a7ef-4838-d9d2-7211123a5674"
      },
      "source": [
        "# load data and change is_churn column into label column\r\n",
        "\r\n",
        "isOnColab = True # CHANGE THIS VARIABLE IF RUNNING ON DATAPROC\r\n",
        "\r\n",
        "path = '/content/drive/MyDrive/datasets/dsnd-sparkify/ml_df.parquet' if isOnColab else 'gs://udacity-dsnd/ml_df.parquet'\r\n",
        "df = spark.read.parquet(path)\r\n",
        "df = df.withColumn('label', F.when(F.col(\"is_churn\"), 1).otherwise(0))\r\n",
        "df.show(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------------------+--------+----------+-------------+------------------+----------+-----------+---------+------------------+----------+-----+------+-----+-----+-------+-------+------------+-------------+----------+------------+-----+\n",
            "| userId|              up_ts|is_churn|song_count|subs_duration|         song_rate|n_playlist|thumbs_down|thumbs_up|      avg_sess_len|sess_count| ipad|iphone|linux|macos|windows|n_error|n_friend_add|n_cancel_page|n_unq_song|n_unq_artist|label|\n",
            "+-------+-------------------+--------+----------+-------------+------------------+----------+-----------+---------+------------------+----------+-----+------+-----+-----+-------+-------+------------+-------------+----------+------------+-----+\n",
            "|1071843|2018-11-08 13:16:59|   false|      1190|           22| 54.09090909090909|        39|          6|       51|27020.272727272728|        11|false| false|false| true|  false|      1|          32|            0|      1104|         902|    0|\n",
            "|1120784|2018-10-11 14:16:28|   false|      1502|           50|             30.04|        45|         17|      122|14162.807692307691|        26|false| false|false|false|   true|      2|          24|            0|      1357|        1042|    0|\n",
            "|1128522|2018-11-13 17:46:22|    true|       203|            2|             101.5|         9|          6|       12|17188.666666666668|         3|false| false|false| true|  false|      0|           4|            0|       198|         190|    1|\n",
            "|1130061|2018-10-11 20:04:50|   false|        96|           50|              1.92|         4|          4|        3|           11930.5|         2|false| false|false| true|  false|      0|           2|            1|        96|          92|    0|\n",
            "|1135039|2018-10-04 11:31:06|   false|       643|           57|11.280701754385966|        29|          4|       49|22156.285714285714|         7|false| false|false|false|   true|      2|          12|            0|       611|         513|    0|\n",
            "+-------+-------------------+--------+----------+-------------+------------------+----------+-----------+---------+------------------+----------+-----+------+-----+-----+-------+-------+------------+-------------+----------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylNDE12FGkVa"
      },
      "source": [
        "### Vectorize Features and Select Only Needed Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EfHC4lrrGTZ"
      },
      "source": [
        "# features columns\r\n",
        "feature_cols = df.columns[3:-1]\r\n",
        "\r\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\r\n",
        "df = assembler.transform(df)\r\n",
        "\r\n",
        "# take only features and label column\r\n",
        "df = df.select([\"features\", \"label\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_O9EqlSHUuy"
      },
      "source": [
        "### Split Dataframe for Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5FA-3RtNBDH"
      },
      "source": [
        "train_df, test_df = df.randomSplit([0.9,0.1], seed=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIDXeXPi98-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e6da0d-3345-42cf-b2c1-1a2cc59ce2cf"
      },
      "source": [
        "print(\"train\")\r\n",
        "train_df.groupby(\"label\").count().show()\r\n",
        "\r\n",
        "print(\"test\")\r\n",
        "test_df.groupby(\"label\").count().show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    1| 4470|\n",
            "|    0| 9148|\n",
            "+-----+-----+\n",
            "\n",
            "test\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    1|  480|\n",
            "|    0| 1037|\n",
            "+-----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_aLTZ5BHqIw"
      },
      "source": [
        "We have around 1:2 ratio between 1 and 0 label. It shows that we have balanced train and test data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLmhv25MH7kb"
      },
      "source": [
        "### Build Grid Search, Train Model and Predict Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTv5ivs0DeFY"
      },
      "source": [
        "# gradient boosted tree algorithm\r\n",
        "gbt = GBTClassifier()\r\n",
        "\r\n",
        "# Grid search parameter\r\n",
        "gbt_grid = ParamGridBuilder() \\\r\n",
        "    .addGrid(gbt.maxDepth, [4, 5, 6]) \\\r\n",
        "    .addGrid(gbt.maxIter, [15, 20, 25]) \\\r\n",
        "    .build()\r\n",
        "\r\n",
        "# train validation split to search through all grid\r\n",
        "gbt_tvs = TrainValidationSplit(estimator=gbt,\r\n",
        "                            estimatorParamMaps=gbt_grid,\r\n",
        "                            evaluator=BinaryClassificationEvaluator(),\r\n",
        "                            trainRatio=0.75,\r\n",
        "                            seed=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHuzEdiboihn"
      },
      "source": [
        "# train model\r\n",
        "gbt_model = gbt_tvs.fit(train_df)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbMGwAhoOQly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b655bfe-1b32-49f3-ac5c-7471ef60de74"
      },
      "source": [
        "gbt_model.bestModel"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GBTClassificationModel: uid = GBTClassifier_de3b32670a8c, numTrees=25, numClasses=2, numFeatures=18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVOr7nfjfkxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bfa2a3c-1e93-4384-adfa-dcabfac979a7"
      },
      "source": [
        "gbt_model.bestModel.featureImportances"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(18, {0: 0.0001, 1: 0.3445, 2: 0.1394, 3: 0.0052, 4: 0.0234, 5: 0.0262, 6: 0.0928, 7: 0.1744, 8: 0.0003, 13: 0.0009, 14: 0.0033, 15: 0.1882, 16: 0.0013})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKUp1fhoIfMh"
      },
      "source": [
        "As seen above, the most important feature in gradient boost model are number 1 (subscription duration) with value 0.3445, number 2 (songs heard per day of subscription) with value 0.1394, number 7 (sessions count) with value 0.1744 and number 15 (cancel confirmation visit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw21yapEuc9F"
      },
      "source": [
        "# predict on test dataframe\r\n",
        "preds_df = gbt_model.transform(test_df)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRdGkgzlJot6"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0jRiyXdE501"
      },
      "source": [
        "def evaluate(df, label_col='label', pred_col='prediction'):\r\n",
        "    '''\r\n",
        "    INPUT:\r\n",
        "    df - spark dataframe\r\n",
        "    label_col - name of label column\r\n",
        "    pred_col - name of prediction column\r\n",
        "\r\n",
        "    OUTPUT:\r\n",
        "    res - pandas dataframe of metrics\r\n",
        "    '''\r\n",
        "\r\n",
        "    temp_df = df.select([label_col, pred_col]).toPandas()\r\n",
        "    \r\n",
        "    return pd.DataFrame.from_dict({\r\n",
        "        \"accuracy\" : [accuracy_score(temp_df[label_col], temp_df[pred_col])],\r\n",
        "        \"precision\" : [precision_score(temp_df[label_col], temp_df[pred_col])],\r\n",
        "        \"recall\" : [recall_score(temp_df[label_col], temp_df[pred_col])],\r\n",
        "        \"f1\" : [f1_score(temp_df[label_col], temp_df[pred_col])],\r\n",
        "        \"roc_auc\" : [roc_auc_score(temp_df[label_col], temp_df[pred_col])],\r\n",
        "    })"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "n9XhLF4LAQj3",
        "outputId": "8ae13956-f478-40e0-e4e0-f15ef0d926f8"
      },
      "source": [
        "# metrics result\r\n",
        "evaluate(preds_df)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.78708</td>\n",
              "      <td>0.663202</td>\n",
              "      <td>0.664583</td>\n",
              "      <td>0.663892</td>\n",
              "      <td>0.754182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  precision    recall        f1   roc_auc\n",
              "0   0.78708   0.663202  0.664583  0.663892  0.754182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrBEolvJKJ61",
        "outputId": "7e99b14f-3f41-4644-fffe-6deee430b6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# confusion matrix\r\n",
        "confusion_matrix(preds_df.select(\"label\").toPandas(),\r\n",
        "                preds_df.select(\"prediction\").toPandas())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[875, 162],\n",
              "       [161, 319]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Kxtg8xMlbe"
      },
      "source": [
        "With metrics shown above, the result is good enough to make churn prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocWt0oeAfB8-"
      },
      "source": [
        "model.save('/content/drive/MyDrive/datasets/dsnd-sparkify/sparkify_model')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}